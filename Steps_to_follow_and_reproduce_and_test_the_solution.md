# âœ… Business Requirements & Constraints Covered

## Prerequisites
- Windows 10 or 11  
- Python 3.10+ installed  
- Git installed  
- Visual Studio Code installed  
- Command Prompt or PowerShell access  
- At least 500 MB free disk space  
- Sample CSV/XLSX file matching the schema  

## ðŸ”’ Data & Trust
- 100% local execution (localhost only)
- No cloud, no telemetry, no external APIs
- Data never leaves your machine
- Fully auditable and explainable processing

## ðŸ—‚ Data Intake & Pre-Processing
- Accepts only CSV/XLSX files
- Deterministic auto-fix (trim, casing, dates, dedup, etc.)
- All changes logged in audit reports
- AI never reads files directly

## ðŸ›¡ Schema Validation
- Strict schema, type, format, and null checks
- Processing stops on failure with clear errors

## ðŸ“Š Phase-1 Analytics
- Rule-based, explainable scoring and metrics
- No black-box models

## ðŸ’¾ Outputs & Storage
- All outputs saved locally
- Cleaned data, audit logs, validation reports

## ðŸ–¥ Localhost UI
- Simple, executive-friendly dashboard
- Fully offline and secure

## ðŸ“‹ Deliverables & Style
- Clear diagrams, schemas, and output templates
- Minimal dependencies
- Plain language, icons, and short sections

## ðŸ— Architecture Overview
```
[User] â†’ [Localhost UI] â†’ [Auto-fix Engine] â†’ [Schema Validator] â†’ [Analytics Engine] â†’ [Local Outputs]
```
**Summary:** A fully local, secure, auditable, and business-safe solution with zero cloud dependency and complete transparency.

## ðŸ“¦ Artifacts & Outputs

- `05-Outputs/cleaned-data.csv` - Cleaned and auto-fixed data
- `05-Outputs/autofix-audit/audit-log.json` - Log of all auto-fix actions
- `05-Outputs/validation-reports/report.json` - Schema validation results

**How to download:** Download cleaned data and reports directly from the UI, or find them in the `05-Outputs` folder.

**Unified E2E Workflow:**
- Run the pipeline and UI together with:
  ```powershell
  cd 01-Scripts
  .\RUN-ALL-AND-UI.ps1 -InputFile "..\DataFiles\sample-data.csv"
  ```
- The script will clean, validate, and launch the UI.
- If you see an error about missing cleaned-data.csv, check that your input file exists and is readable.
- The script now checks and throws a clear error if cleaned-data.csv is not created.

**Auto-fix:** Trims headers/values, normalizes casing, standardizes dates, coerces numbers, normalizes categories, and removes empty/duplicate rows. All actions are logged in `audit-log.json`.

**Validation:** Checks required columns, data types, allowed values, date formats, and null thresholds. If validation fails, processing stops and a clear error is shown in the UI and `report.json`.

---

# Steps to follow and reproduce and test the solution

## After Auto-fix & Validation

### After Quick Start or Before Full Setup
**Add:**
### ðŸ–¥ UI Features
- ðŸ“‚ Local file selection and upload
- ðŸ§¹ Auto-fix summary and audit log
- âœ…âŒ Schema validation status (with errors/warnings)
- ðŸ“Š Data quality summary
- ðŸ§  Analytics results (priority, risk, opportunity)
- ðŸ“¥ Downloadable outputs
- ðŸ•’ Run metadata (timestamp, row count, etc.)

### After Install dependencies in Full Setup
**Add:**
### ðŸ“š Dependency Justification
- `pandas` - Data loading and cleaning
- `flask` - Local web UI
- `jsonschema` - Schema validation
- `openpyxl` - Excel file support

---

## To check which setup steps you need and get detailed info or commands, follow these tips:
For each step, run the commands in the Visual Studio Code Terminal (bottom panel, tab named "Terminal").

### How to do it:

1. Open Visual Studio Code.
2. Open the Terminal (menu: View > Terminal).
3. Make sure you are in the Phase1-LocalInsights folder. If not, use:
   ```
   CD C:\MyCode\cx-ai-local\LocalAIAgent-Phase1
   ```

**Output Window:**

### 2. Create and activate a Python virtual environment:
```bash
py -3.11 -m venv .venv311
.venv311\Scripts\activate
```

### 3. Install required dependencies (If not there)
```bash
pip install --upgrade pip
pip install pandas==2.1.4 flask==3.0.0 jsonschema==4.20.0 openpyxl==3.1.2
```

### 4. Once successfully installed required dependencies.

### 5. Ensure output folders exist:
```powershell
if (-not (Test-Path "05-Outputs\autofix-audit")) { New-Item -ItemType Directory -Path "05-Outputs\autofix-audit" -Force }
if (-not (Test-Path "05-Outputs\validation-reports")) { New-Item -ItemType Directory -Path "05-Outputs\validation-reports" -Force }
```

### 6. The setup checks for the following folders inside your project directory:
- autofix-audit
- validation-reports

#### Why These Folders Are Checked
These folders are required for saving the results generated by the pipeline:
- **autofix-audit**: Stores audit logs of data cleaning actions
- **validation-reports**: Stores data validation reports

#### Why It Matters
The application requires these folders to exist before writing any output. If they are missing, file writes will fail.

#### If Missing
- Pipeline/UI may throw errors or crash
- Output files like audit-log.json and report.json won't be created
- You must manually create the folders and rerun the pipeline

### 7. The next step is to start the UI application so you can use the web dashboard to upload files and run the pipeline.

Here's what to do:
Navigate to the UI folder:
```bash
cd C:\MyCode\cx-ai-local\LocalAIAgent-Phase1
```

Next steps:
Navigate to the UI folder:
```bash
cd 04-UI
```

### 8. Start the Flask app:
```bash
python app.py
```

**Why needed:**
Starts the Local Insights Dashboard (web UI) for your data pipeline.

**Purpose:**
Provides a browser-based interface to:
- Upload CSV/Excel files
- Run data cleaning and validation
- View cleaned data, audit logs, and validation reports

## âœ… Business Requirements & Constraints Covered
### ðŸ”’ Data & Trust
- 100% local execution (localhost only)
- No cloud, no telemetry, no external APIs
- Data never leaves your machine
- Fully auditable and explainable processing

### ðŸ—‚ Data Intake & Pre-Processing
- Accepts only CSV/XLSX files
- Deterministic auto-fix (trim, casing, dates, dedup, etc.)
- All changes logged in audit reports
- AI never reads files directly

### ðŸ›¡ Schema Validation
- Strict schema, type, format, and null checks
- Processing stops on failure with clear errors

### ðŸ“Š Phase-1 Analytics
- Rule-based, explainable scoring and metrics
- No black-box models

### ðŸ’¾ Outputs & Storage
- All outputs saved locally
- Cleaned data, audit logs, validation reports

### ðŸ–¥ Localhost UI
- Simple, executive-friendly dashboard
- Fully offline and secure

### ðŸ“‹ Deliverables & Style
- Clear diagrams, schemas, and output templates
- Minimal dependencies
- Plain language, icons, and short sections

#### How to run
1. Activate your virtual environment
2. Go to the 04-UI folder
3. Run the command
4. Open: http://127.0.0.1:5000

### 9. Dashboard Started Successfully
Access it at: http://127.0.0.1:5000

#### Next Steps
**Upload a File**
- Click Choose File
- Select a CSV or Excel file (max 16 MB, must match schema)
- Click Upload File

**Run the Pipeline**
- Find your file under Available Files for Testing
- Click Run Pipeline

**Review Results**
- View results directly in the dashboard
- Output files are saved in 05-Outputs:
  - cleaned-data.csv
  - autofix-audit/audit-log.json
  - validation-reports/report.json

**(Optional) Download Outputs**
- Download from the UI or open them from the output folder
