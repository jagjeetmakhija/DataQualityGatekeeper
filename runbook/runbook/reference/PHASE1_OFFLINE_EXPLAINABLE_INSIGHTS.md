# Phase-1 (POV) ‚Äî Offline, Explainable, Directional Predictive Insights (Localhost Only)

> **Scope:** Phase-1 proof-of-value (directional insights), **NOT** a production ML system.  
> **Runtime:** 100% localhost / offline-capable.  
> **Model:** *Foundry Local* (example: phi-4) running on **CPU or GPU** locally.

---

## ‚úÖ Non‚ÄëNegotiable Trust Constraints (Built‚Äëin)

üîê **Data & Trust**
- Confidential data stays on the machine (no sharing).
- **No external connections**: no external APIs, no plugins, no uploads.
- **No telemetry**: no background reporting.
- **Predictable cost**: local execution only; no hidden usage meters.
- **Explainable outputs**: rules/heuristics + ‚Äúwhy‚Äù drivers (no black‚Äëbox scoring).

üö´ **Explicitly forbidden**
- Any remote AI endpoints
- Public APIs
- Auto-upload or sync
- Browser AI tools
- Background processes that can create cost surprises

---

## 1) Text Architecture Diagram (Simple + Auditable)

```
[User / Stakeholder]                         (Local machine only)
        |
        | 1) selects local file (CSV/XLSX/TXT)
        v
[Local Intake Loader (non‚ÄëAI)]
        |
        | 2) deterministic auto-fix (logged)
        v
[Auto‚ÄëFix Engine] ---> writes ---> outputs/audit/AUTOFIX_AUDIT_REPORT.json
        |
        | 3) schema validation gate (PASS/FAIL)
        v
[Schema Validator] ---> writes ---> outputs/validation/PHASE1_VALIDATION_REPORT.json
        |
        | FAIL => STOP + actionable error
        | PASS => continue
        v
[Snippet Generator (non‚ÄëAI)]  (50‚Äì100 rows max, redacted/limited)
        |
        | 4) user-controlled prompt + snippet
        v
[Foundry Local Model (offline)]  ---> returns ---> [Explainable Drafts]
        |
        | 5) rules-based scoring + drivers
        v
[Insights Generator]
        |
        +--> outputs/insights/RANKED_INSIGHTS.csv
        +--> outputs/insights/SCORING_DEFINITIONS.md
        +--> outputs/insights/SUCCESS_METRICS.md
        +--> outputs/data_quality/DATA_QUALITY_SUMMARY.json
        +--> outputs/run_metadata/RUN_METADATA.json
```

---

## 2) Clean Module / Folder Structure

Recommended project layout:

```
<project-root>/
  data/                         # input files (local only)
  Validation/
    Schemas/                    # schema definitions (yaml/json)
    Reports/                    # validation outputs
  outputs/
    audit/
    validation/
    converted/                  # cleaned datasets
    snippets/
    insights/
    data_quality/
    run_metadata/
  ui/                           # thin local UI (optional)
  runbook/
    setup/
    pipeline/
    testing/
    audit/
    troubleshooting/
    reference/                  # this doc + schemas + templates
```

---

## 3) Minimal Dependencies (Phase‚Äë1) + Why

**Required**
- **PowerShell 7+**: consistent scripting + portability
- **Python 3.10+** (optional but recommended): robust CSV/XLSX parsing + deterministic cleanup
- **Foundry Local runtime**: local model inference (CPU/GPU), offline

**Avoid (Phase‚Äë1)**
- Heavy ML stacks (training frameworks) ‚Äî not needed for directional scoring
- Anything that requires internet access

---

## 4) Phase‚Äë1 Execution Flow (With Fail Gates)

### Step A ‚Äî Intake (non‚ÄëAI)
- User selects a local file in `data/`
- Loader reads it (CSV/XLSX/TXT) and writes a normalized CSV into:
  - `outputs/converted/converted_phase1.csv`

### Step B ‚Äî Auto‚ÄëFix (deterministic + auditable)
Auto-fix MUST:
- Trim headers and values
- Normalize casing/whitespace
- Standardize dates to ISO (YYYY‚ÄëMM‚ÄëDD) when possible
- Coerce numeric fields safely (`"1,000" ‚Üí 1000`)
- Normalize known categorical synonyms (controlled mapping only)
- Handle delimiter issues (comma/tab)
- Remove/flag empty rows
- De‚Äëduplicate obvious duplicates

**Rules**
- Deterministic only (same input ‚Üí same output)
- No guessing/inventing business values
- Every change is logged in `outputs/audit/`

### Step C ‚Äî Schema Validation Gate (STOP if FAIL)
Validation checks:
- Required columns
- Data types
- Allowed values
- Date formats
- Null thresholds

**If FAIL**
- STOP processing immediately
- Show **actionable** message:
  - what failed
  - why it failed
  - how to fix it
- Save a FAIL report:
  - `outputs/validation/PHASE1_VALIDATION_REPORT.json`

**If PASS**
- Proceed to snippet generation + Phase‚Äë1 analysis

### Step D ‚Äî Controlled Model Usage (user‚Äëcontrolled)
- Model NEVER reads files
- User provides ONLY a limited snippet (50‚Äì100 rows max)
- Snippet is created by a local snippet generator and saved under:
  - `outputs/snippets/snippet_phase1.txt`
- Internet OFF

### Step E ‚Äî Phase‚Äë1 Analytics Outputs (Explainable)
Generate:
1) **Directional scoring definitions**
   - Account Priority (High/Medium/Low)
   - Activation Likelihood band
   - Stalling / Risk indicators
2) **CX-aligned success metrics** (draft KPIs)
3) **Ranked insights**
   - top opportunities
   - top risks
   - drivers (‚Äúwhy‚Äù)
4) **Data quality summary** + validation results

---

## 5) Example Schema Definition (YAML)

See: `runbook/reference/schema_phase1.yaml`

---

## 6) Explainable Scoring Logic (Rules / Heuristics)

**Important:** Directional scoring only ‚Äî not statistical prediction.

### Example rule set (illustrative)
**Account Priority**
- High:
  - Stage in {Negotiation, Proposal} AND
  - Value >= threshold AND
  - LastActivityDate within last N days
- Medium:
  - Stage in {Discovery, Qualification} OR
  - Value moderate AND activity recent
- Low:
  - Low value OR no recent activity OR missing key fields

**Activation Likelihood Band**
- High:
  - Activation milestones completed count >= X
  - No blocked dependencies
- Medium:
  - Some milestones completed, some pending
- Low:
  - Many pending + long inactivity + high nulls in critical fields

**Stalling / Risk Indicators**
- ‚ÄúStale activity‚Äù: LastActivityDate older than N days
- ‚ÄúStage stagnation‚Äù: StageAgeDays > threshold
- ‚ÄúData risk‚Äù: key columns null rate > threshold
- ‚ÄúValue mismatch‚Äù: High value but no progress signals

**Explainability rule**
- Every score MUST output:
  - triggered rules
  - fields used
  - driver text (‚Äúwhy this was ranked‚Äù)

---

## 7) Sample Output Templates

### Ranked Insights table (CSV)
- `OpportunityRank`
- `AccountId`
- `AccountName`
- `PriorityBand`
- `RiskBand`
- `TopDrivers` (semicolon-separated)
- `RecommendedNextAction`
- `ConfidenceNote` (directional)

### Validation report (JSON)
- `OverallStatus`: PASS/FAIL
- `FailedChecks`: list with `check`, `column`, `reason`, `fix`
- `Summary`: row counts, duplicates removed, quality score

### Run metadata (JSON)
- `timestamp`
- `model_name`
- `device` (CPU/GPU)
- `rows_in`
- `rows_after_autofix`
- `snippet_rows_sent_to_model`

---

## 8) CX Trust Checklist (Phase‚Äë1 Proof)

‚úÖ Offline execution
- All steps run locally (no remote calls)

‚úÖ No data exposure
- Inputs/outputs remain on disk locally
- No external dependencies that transmit data

‚úÖ No black‚Äëbox behavior
- Directional scoring = explicit rules + drivers
- Model used only for drafting text explanations from limited snippets

‚úÖ No cost surprises
- Local compute only (CPU/GPU)
- No metered remote usage

‚úÖ Full auditability
- Auto-fix audit report saved
- Validation report saved (PASS/FAIL)
- Run metadata saved
